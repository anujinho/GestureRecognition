{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T19:16:07.161273Z",
     "start_time": "2020-08-06T19:15:47.541015Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n",
      "True\n",
      "WARNING:tensorflow:From <ipython-input-1-1b342841ad38>:5: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "#Check GPU and CUDA Compatibility\n",
    "print(tf.__version__)\n",
    "print(tf.test.is_built_with_cuda())\n",
    "print(tf.test.is_gpu_available(cuda_only=False, min_cuda_compute_capability=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T18:28:34.322218Z",
     "start_time": "2020-08-10T18:28:34.306261Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import array_to_img\n",
    "from tensorflow.keras import losses\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import string\n",
    "import glob\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Creation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T20:39:22.003353Z",
     "start_time": "2020-08-10T20:39:21.987327Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./Hand_Gest_Recog/data\\\\00',\n",
       " './Hand_Gest_Recog/data\\\\01',\n",
       " './Hand_Gest_Recog/data\\\\02',\n",
       " './Hand_Gest_Recog/data\\\\03',\n",
       " './Hand_Gest_Recog/data\\\\04',\n",
       " './Hand_Gest_Recog/data\\\\05',\n",
       " './Hand_Gest_Recog/data\\\\06',\n",
       " './Hand_Gest_Recog/data\\\\07',\n",
       " './Hand_Gest_Recog/data\\\\08',\n",
       " './Hand_Gest_Recog/data\\\\09']"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list = glob.glob(\"./Hand_Gest_Recog/data/*\")\n",
    "data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T20:40:19.001264Z",
     "start_time": "2020-08-10T20:39:49.573381Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:29<00:00,  2.94s/it]\n"
     ]
    }
   ],
   "source": [
    "for cand in tqdm(data_list):\n",
    "    d = cand + '/*'\n",
    "    for gest_type in glob.glob(d):\n",
    "        d1 = gest_type + '/*'\n",
    "        imgs = glob.glob(d1)\n",
    "        images_train = random.sample(imgs, k=160)\n",
    "        images_test = list(set(imgs) - set(images_train))\n",
    "        images_valid = random.sample(images_train, k=32)\n",
    "        images_train = list(set(images_train) - set(images_valid))\n",
    "        for (i, j, k) in itertools.zip_longest(images_train, images_valid,\n",
    "                                               images_test):\n",
    "            s = r'C:/Users/Anuj/Desktop/Work/Data Science/Deep_Learning/Supervised Deep Learning/Part 2 - Convolutional Neural Networks (CNN)/Hand_Gest_Recog/train/' + i[\n",
    "                26:28] + '/'\n",
    "            shutil.copy(i, s)\n",
    "            if (j != None) and (k != None):\n",
    "                s1 = r'C:/Users/Anuj/Desktop/Work/Data Science/Deep_Learning/Supervised Deep Learning/Part 2 - Convolutional Neural Networks (CNN)/Hand_Gest_Recog/valid/' + j[\n",
    "                    26:28] + '/'\n",
    "                s2 = r'C:/Users/Anuj/Desktop/Work/Data Science/Deep_Learning/Supervised Deep Learning/Part 2 - Convolutional Neural Networks (CNN)/Hand_Gest_Recog/test/' + k[\n",
    "                    26:28] + '/'\n",
    "                shutil.copy(j, s1)\n",
    "                shutil.copy(k, s2)\n",
    "            else:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Investigating Image Properties "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T20:11:07.245539Z",
     "start_time": "2020-08-10T20:11:05.496589Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'PIL.Image.Image'>\n",
      "None\n",
      "RGB\n",
      "(640, 240)\n"
     ]
    }
   ],
   "source": [
    "# load the image\n",
    "img = load_img(\n",
    "    './Hand_Gest_Recog/train/01/frame_00_01_0091.png'\n",
    "    #target_size = (500,500)\n",
    ")\n",
    "# report details about the image\n",
    "print(type(img))\n",
    "print(img.format)\n",
    "print(img.mode)\n",
    "print(img.size)\n",
    "# show the image\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T20:11:20.974432Z",
     "start_time": "2020-08-10T20:11:20.958443Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 640, 3)\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "img_array = img_to_array(img)\n",
    "print(img_array.shape)\n",
    "print(img_array.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-06T20:45:29.069120Z",
     "start_time": "2020-08-06T20:45:29.045137Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 6.,  6.,  6.],\n",
       "        [ 5.,  5.,  5.],\n",
       "        [ 6.,  6.,  6.],\n",
       "        ...,\n",
       "        [ 3.,  3.,  3.],\n",
       "        [ 6.,  6.,  6.],\n",
       "        [ 3.,  3.,  3.]],\n",
       "\n",
       "       [[ 6.,  6.,  6.],\n",
       "        [ 5.,  5.,  5.],\n",
       "        [ 6.,  6.,  6.],\n",
       "        ...,\n",
       "        [ 3.,  3.,  3.],\n",
       "        [ 6.,  6.,  6.],\n",
       "        [ 3.,  3.,  3.]],\n",
       "\n",
       "       [[ 5.,  5.,  5.],\n",
       "        [ 4.,  4.,  4.],\n",
       "        [ 6.,  6.,  6.],\n",
       "        ...,\n",
       "        [ 2.,  2.,  2.],\n",
       "        [ 2.,  2.,  2.],\n",
       "        [ 4.,  4.,  4.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 4.,  4.,  4.],\n",
       "        [ 5.,  5.,  5.],\n",
       "        [ 4.,  4.,  4.],\n",
       "        ...,\n",
       "        [ 4.,  4.,  4.],\n",
       "        [ 3.,  3.,  3.],\n",
       "        [ 4.,  4.,  4.]],\n",
       "\n",
       "       [[ 4.,  4.,  4.],\n",
       "        [ 5.,  5.,  5.],\n",
       "        [ 5.,  5.,  5.],\n",
       "        ...,\n",
       "        [10., 10., 10.],\n",
       "        [12., 12., 12.],\n",
       "        [20., 20., 20.]],\n",
       "\n",
       "       [[ 4.,  4.,  4.],\n",
       "        [ 5.,  5.,  5.],\n",
       "        [ 5.,  5.,  5.],\n",
       "        ...,\n",
       "        [10., 10., 10.],\n",
       "        [12., 12., 12.],\n",
       "        [20., 20., 20.]]], dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T20:45:12.303848Z",
     "start_time": "2020-08-10T20:45:10.832255Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "0koUcJMJpEBD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12800 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "training_set = train_datagen.flow_from_directory('./Hand_Gest_Recog/train/',\n",
    "                                                 target_size = (200,200),\n",
    "                                                 batch_size = 32,\n",
    "                                                 color_mode = 'grayscale',\n",
    "                                                 class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T20:45:17.234485Z",
     "start_time": "2020-08-10T20:45:16.855031Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3200 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "validating_set = valid_datagen.flow_from_directory('./Hand_Gest_Recog/valid/',\n",
    "                                                 target_size = (200,200),\n",
    "                                                 batch_size = 32,\n",
    "                                                 color_mode = 'grayscale',\n",
    "                                                 class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T20:45:22.798368Z",
     "start_time": "2020-08-10T20:45:22.391305Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "SH4WzfOhpKc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3200 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_set = test_datagen.flow_from_directory('./Hand_Gest_Recog/test/',\n",
    "                                            target_size = (200,200),\n",
    "                                            batch_size = 1,\n",
    "                                            color_mode = 'grayscale',\n",
    "                                            class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T20:48:56.847301Z",
     "start_time": "2020-08-10T20:48:56.486184Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 98, 98, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 49, 49, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               589952    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 634,346\n",
      "Trainable params: 634,346\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=5, strides=2, activation='relu', input_shape=[200, 200, 1]),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=2, strides=2),\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=2, activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=2, strides=2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=2000, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=1000, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=500, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=10, activation='sigmoid')\n",
    "])\n",
    "\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T20:51:44.523832Z",
     "start_time": "2020-08-10T20:51:44.278826Z"
    }
   },
   "outputs": [],
   "source": [
    "cnn.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T21:00:23.976001Z",
     "start_time": "2020-08-10T20:52:44.370655Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "400/400 [==============================] - 97s 243ms/step - loss: 0.7882 - accuracy: 0.7189 - val_loss: 0.1795 - val_accuracy: 0.9413.1971 - accuracy - ETA: 35s - loss: 1.17 - ETA: 31s - loss: 1.1106 - accuracy: 0 - ETA: 30s - loss: 1.0962 - accuracy: 0.60 - ETA: 30s - loss: - ETA: 24s - loss: 1.0216 - accuracy: 0.634 - ETA: 24s - loss: 1.0 - ETA: 20s - loss: 0.9714 - accuracy: 0 - ETA: 19s - ETA: 2s - loss:\n",
      "Epoch 2/15\n",
      "400/400 [==============================] - 85s 214ms/step - loss: 0.1435 - accuracy: 0.9502 - val_loss: 0.0670 - val_accuracy: 0.9791\n",
      "Epoch 3/15\n",
      "400/400 [==============================] - 93s 232ms/step - loss: 0.0692 - accuracy: 0.9759 - val_loss: 0.0754 - val_accuracy: 0.9741\n",
      "Epoch 4/15\n",
      "400/400 [==============================] - 88s 220ms/step - loss: 0.0536 - accuracy: 0.9826 - val_loss: 0.1009 - val_accuracy: 0.9672\n",
      "Epoch 5/15\n",
      "400/400 [==============================] - 87s 218ms/step - loss: 0.0431 - accuracy: 0.9871 - val_loss: 0.2251 - val_accuracy: 0.9484\n",
      "Epoch 00005: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x140be716d30>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(x = training_set, validation_data = validating_set, epochs = 15, callbacks = [es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T21:02:06.205929Z",
     "start_time": "2020-08-10T21:01:50.319312Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1/3200 [..............................] - ETA: 0s - loss: 1.0014e-05 - accuracy: 1.0000WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0113s). Check your callbacks.\n",
      "3200/3200 [==============================] - 16s 5ms/step - loss: 0.1726 - accuracy: 0.9606 0s - loss: 0.1720 - accuracy: 0.\n"
     ]
    }
   ],
   "source": [
    "[loss, acc] = cnn.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-10T21:02:23.310198Z",
     "start_time": "2020-08-10T21:02:23.306240Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.06249928474426\n"
     ]
    }
   ],
   "source": [
    "print(acc*100)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
